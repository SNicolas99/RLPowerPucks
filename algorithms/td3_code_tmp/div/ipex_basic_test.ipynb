{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gekeleda/mambaforge/envs/rl/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using xpu device\n",
      "using xpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gekeleda/mambaforge/envs/rl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"intel_extension_for_pytorch\") is not None:\n",
    "    import intel_extension_for_pytorch as ipex\n",
    "    ipex_available = True\n",
    "else:\n",
    "    ipex_available = False\n",
    "\n",
    "# ipex_available = False ### FOR TESTING PURPOSES\n",
    "if ipex_available and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "    print(\"using xpu device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    ipex_available = False\n",
    "    print(\"using cpu device\")\n",
    "\n",
    "from torch import nn\n",
    "from Q_file import Q_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Q_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2158e-01, 2.3145e-01, 3.7891e-01],\n",
       "         [8.7109e-01, 8.7891e-01, 3.7305e-01],\n",
       "         [6.7578e-01, 6.7969e-01, 7.9688e-01],\n",
       "         [9.4922e-01, 8.7500e-01, 7.5378e-03],\n",
       "         [3.6377e-02, 9.8438e-01, 6.3281e-01],\n",
       "         [5.7031e-01, 4.3750e-01, 1.8555e-01],\n",
       "         [7.3828e-01, 7.8906e-01, 7.8125e-01],\n",
       "         [9.4531e-01, 9.8438e-01, 5.8594e-01],\n",
       "         [8.0859e-01, 1.9336e-01, 7.4707e-02],\n",
       "         [7.1094e-01, 5.3516e-01, 7.8125e-01],\n",
       "         [7.6294e-03, 6.6797e-01, 5.1172e-01],\n",
       "         [8.9844e-01, 1.0000e+00, 7.2656e-01],\n",
       "         [1.0010e-01, 3.0469e-01, 7.7734e-01],\n",
       "         [7.1875e-01, 7.0703e-01, 1.0840e-01],\n",
       "         [4.0039e-01, 8.1641e-01, 6.9141e-01],\n",
       "         [6.3672e-01, 2.3242e-01, 2.4902e-01],\n",
       "         [8.5547e-01, 5.0391e-01, 2.6758e-01],\n",
       "         [6.4844e-01, 6.9922e-01, 7.5781e-01],\n",
       "         [6.2891e-01, 5.5859e-01, 3.9062e-01],\n",
       "         [1.6992e-01, 5.5469e-01, 1.4648e-01],\n",
       "         [6.6406e-01, 2.5586e-01, 7.1777e-02],\n",
       "         [5.1172e-01, 6.3281e-01, 8.3203e-01],\n",
       "         [7.7344e-01, 8.8281e-01, 3.9844e-01],\n",
       "         [3.6719e-01, 3.4570e-01, 2.4414e-01],\n",
       "         [6.6406e-01, 5.4297e-01, 2.8711e-01],\n",
       "         [2.2363e-01, 3.4766e-01, 6.2109e-01],\n",
       "         [8.0859e-01, 4.7607e-02, 3.7891e-01],\n",
       "         [5.3125e-01, 9.6875e-01, 8.9844e-01],\n",
       "         [4.2578e-01, 7.5000e-01, 9.4531e-01],\n",
       "         [5.1562e-01, 8.6719e-01, 1.0205e-01],\n",
       "         [8.0078e-01, 9.6875e-01, 9.1406e-01],\n",
       "         [7.6953e-01, 8.4375e-01, 6.7871e-02],\n",
       "         [3.1445e-01, 9.4141e-01, 9.1797e-01],\n",
       "         [7.3047e-01, 1.5820e-01, 1.0400e-01],\n",
       "         [5.5078e-01, 8.6719e-01, 3.7695e-01],\n",
       "         [2.2949e-01, 8.3496e-02, 8.8672e-01],\n",
       "         [7.4219e-01, 2.6758e-01, 2.6172e-01],\n",
       "         [1.5723e-01, 1.5039e-01, 7.8125e-01],\n",
       "         [8.2422e-01, 5.1953e-01, 2.8320e-01],\n",
       "         [2.1973e-01, 7.3438e-01, 8.7109e-01],\n",
       "         [2.0996e-01, 4.1504e-02, 1.4160e-01],\n",
       "         [2.8125e-01, 4.8242e-01, 5.2002e-02],\n",
       "         [2.5586e-01, 9.3750e-01, 3.0664e-01],\n",
       "         [3.2617e-01, 7.0312e-02, 5.2344e-01],\n",
       "         [4.2969e-01, 1.8164e-01, 4.1406e-01],\n",
       "         [2.9297e-01, 8.5938e-02, 8.7500e-01],\n",
       "         [2.9492e-01, 5.8203e-01, 5.7031e-01],\n",
       "         [5.8203e-01, 9.4141e-01, 8.9844e-02],\n",
       "         [8.3496e-02, 5.3906e-01, 1.2793e-01],\n",
       "         [8.0469e-01, 4.5703e-01, 1.1084e-01],\n",
       "         [5.2344e-01, 9.6094e-01, 7.0703e-01],\n",
       "         [7.9297e-01, 5.2734e-01, 4.8828e-01],\n",
       "         [8.2422e-01, 2.5000e-01, 7.2656e-01],\n",
       "         [4.3945e-01, 5.8594e-01, 7.5391e-01],\n",
       "         [9.4141e-01, 2.4414e-01, 4.3359e-01],\n",
       "         [2.7344e-01, 7.2754e-02, 9.0234e-01],\n",
       "         [9.9219e-01, 9.8047e-01, 3.5156e-02],\n",
       "         [1.5723e-01, 2.3828e-01, 4.7656e-01],\n",
       "         [5.9766e-01, 7.8125e-01, 4.0234e-01],\n",
       "         [1.4844e-01, 7.1484e-01, 5.0781e-01],\n",
       "         [5.4297e-01, 2.5781e-01, 4.3555e-01],\n",
       "         [5.6641e-01, 9.6094e-01, 2.3315e-02],\n",
       "         [3.5352e-01, 8.3203e-01, 1.4551e-01],\n",
       "         [3.4668e-02, 3.8281e-01, 6.6016e-01],\n",
       "         [4.0234e-01, 9.3359e-01, 9.9609e-01],\n",
       "         [7.8125e-01, 5.0391e-01, 4.4434e-02],\n",
       "         [4.5898e-01, 7.8125e-01, 3.1055e-01],\n",
       "         [5.9766e-01, 6.9531e-01, 7.1875e-01],\n",
       "         [5.2344e-01, 3.8281e-01, 6.7578e-01],\n",
       "         [6.7578e-01, 2.9297e-01, 1.2268e-02],\n",
       "         [5.0000e-01, 3.2812e-01, 7.0312e-01],\n",
       "         [4.6875e-01, 6.6797e-01, 8.2422e-01],\n",
       "         [6.4062e-01, 3.2227e-01, 2.5195e-01],\n",
       "         [3.7891e-01, 3.7891e-01, 2.5586e-01],\n",
       "         [9.1406e-01, 2.9297e-01, 9.2773e-03],\n",
       "         [1.8848e-01, 9.2578e-01, 1.5723e-01],\n",
       "         [8.9453e-01, 6.5234e-01, 2.7930e-01],\n",
       "         [5.1562e-01, 4.8438e-01, 1.5918e-01],\n",
       "         [9.9609e-01, 3.7109e-02, 5.2344e-01],\n",
       "         [5.2344e-01, 8.9453e-01, 8.8672e-01],\n",
       "         [2.1289e-01, 9.1406e-01, 4.7656e-01],\n",
       "         [1.7383e-01, 5.8984e-01, 4.5703e-01],\n",
       "         [4.9414e-01, 3.3594e-01, 8.4766e-01],\n",
       "         [4.1797e-01, 9.2188e-01, 6.9922e-01],\n",
       "         [4.5508e-01, 7.7734e-01, 7.5781e-01],\n",
       "         [5.7031e-01, 3.0078e-01, 6.7188e-01],\n",
       "         [7.3047e-01, 5.8594e-01, 2.1484e-01],\n",
       "         [6.8750e-01, 6.0156e-01, 4.1211e-01],\n",
       "         [4.4727e-01, 9.2578e-01, 4.0430e-01],\n",
       "         [8.4766e-01, 3.6328e-01, 1.6211e-01],\n",
       "         [8.8672e-01, 9.6094e-01, 3.0273e-01],\n",
       "         [5.2344e-01, 2.4121e-01, 3.7500e-01],\n",
       "         [1.3770e-01, 1.1963e-01, 6.6797e-01],\n",
       "         [1.7676e-01, 4.8584e-02, 5.5859e-01],\n",
       "         [8.7891e-01, 6.6406e-01, 5.8594e-01],\n",
       "         [1.7188e-01, 6.9531e-01, 7.1094e-01],\n",
       "         [1.1572e-01, 7.5781e-01, 3.7003e-04],\n",
       "         [5.6250e-01, 7.5000e-01, 3.8867e-01],\n",
       "         [8.8281e-01, 8.2812e-01, 2.1777e-01],\n",
       "         [9.3359e-01, 9.5703e-01, 5.7422e-01],\n",
       "         [3.3936e-02, 1.7871e-01, 8.5156e-01],\n",
       "         [7.6172e-01, 2.9688e-01, 1.0254e-01],\n",
       "         [2.0508e-01, 1.4038e-02, 4.0527e-02],\n",
       "         [6.3477e-02, 9.0234e-01, 5.5859e-01],\n",
       "         [7.2754e-02, 8.1641e-01, 3.7598e-02],\n",
       "         [9.3750e-01, 7.6172e-02, 9.0625e-01],\n",
       "         [8.2812e-01, 3.8818e-02, 5.1562e-01],\n",
       "         [9.2188e-01, 1.3867e-01, 8.5156e-01],\n",
       "         [3.4668e-02, 2.4780e-02, 2.6172e-01],\n",
       "         [1.2988e-01, 8.1250e-01, 4.5410e-02],\n",
       "         [4.7070e-01, 6.7188e-01, 1.8750e-01],\n",
       "         [9.4531e-01, 8.8281e-01, 1.9434e-01],\n",
       "         [7.4219e-01, 1.6016e-01, 6.2988e-02],\n",
       "         [9.0625e-01, 5.8594e-01, 5.9375e-01],\n",
       "         [5.2979e-02, 8.6328e-01, 1.0000e+00],\n",
       "         [5.7422e-01, 2.5195e-01, 1.3965e-01],\n",
       "         [4.8438e-01, 2.1582e-01, 4.9609e-01],\n",
       "         [5.0781e-01, 7.2266e-02, 5.0000e-01],\n",
       "         [3.3691e-02, 1.3574e-01, 5.8203e-01],\n",
       "         [8.2812e-01, 2.7539e-01, 9.4922e-01],\n",
       "         [6.2891e-01, 4.3359e-01, 9.2969e-01],\n",
       "         [1.8555e-02, 1.9727e-01, 6.0156e-01],\n",
       "         [6.0547e-01, 4.2578e-01, 6.8359e-01],\n",
       "         [3.3984e-01, 5.8203e-01, 6.0938e-01],\n",
       "         [8.0859e-01, 7.8516e-01, 8.2812e-01],\n",
       "         [1.2988e-01, 8.3594e-01, 1.2598e-01],\n",
       "         [4.4141e-01, 9.2285e-02, 3.8281e-01],\n",
       "         [6.7578e-01, 6.9531e-01, 7.2656e-01]], device='xpu:0',\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[0.6172],\n",
       "         [0.0305],\n",
       "         [0.6641],\n",
       "         [0.2441],\n",
       "         [0.2178],\n",
       "         [0.6758],\n",
       "         [0.4414],\n",
       "         [0.0747],\n",
       "         [0.8047],\n",
       "         [0.5859],\n",
       "         [0.3770],\n",
       "         [0.9805],\n",
       "         [0.2793],\n",
       "         [0.7383],\n",
       "         [0.0962],\n",
       "         [0.1689],\n",
       "         [0.9102],\n",
       "         [0.3066],\n",
       "         [0.9023],\n",
       "         [0.0138],\n",
       "         [0.1768],\n",
       "         [0.5508],\n",
       "         [0.0439],\n",
       "         [0.3340],\n",
       "         [0.8516],\n",
       "         [0.9023],\n",
       "         [1.0000],\n",
       "         [0.9453],\n",
       "         [0.0459],\n",
       "         [0.6016],\n",
       "         [0.1138],\n",
       "         [0.5547],\n",
       "         [0.7812],\n",
       "         [0.4961],\n",
       "         [0.4414],\n",
       "         [0.6680],\n",
       "         [0.4668],\n",
       "         [0.8516],\n",
       "         [0.6641],\n",
       "         [0.4434],\n",
       "         [0.6133],\n",
       "         [0.7852],\n",
       "         [0.8672],\n",
       "         [0.9453],\n",
       "         [0.1455],\n",
       "         [0.2012],\n",
       "         [0.6836],\n",
       "         [0.2148],\n",
       "         [0.7617],\n",
       "         [0.7461],\n",
       "         [0.5430],\n",
       "         [0.4727],\n",
       "         [0.7461],\n",
       "         [0.6836],\n",
       "         [0.2500],\n",
       "         [0.7461],\n",
       "         [0.9297],\n",
       "         [0.9609],\n",
       "         [0.3652],\n",
       "         [0.3770],\n",
       "         [0.8008],\n",
       "         [0.9688],\n",
       "         [0.6875],\n",
       "         [0.7422],\n",
       "         [0.1357],\n",
       "         [0.1011],\n",
       "         [0.5430],\n",
       "         [0.2334],\n",
       "         [0.0825],\n",
       "         [0.9883],\n",
       "         [0.1504],\n",
       "         [0.4805],\n",
       "         [0.9883],\n",
       "         [0.9453],\n",
       "         [0.9141],\n",
       "         [0.0806],\n",
       "         [0.9414],\n",
       "         [0.4395],\n",
       "         [0.6680],\n",
       "         [0.0635],\n",
       "         [0.6250],\n",
       "         [0.7734],\n",
       "         [0.6719],\n",
       "         [0.6172],\n",
       "         [0.9648],\n",
       "         [0.4473],\n",
       "         [0.1270],\n",
       "         [0.1953],\n",
       "         [0.7891],\n",
       "         [0.4082],\n",
       "         [0.7305],\n",
       "         [0.5625],\n",
       "         [0.5469],\n",
       "         [0.1436],\n",
       "         [0.6562],\n",
       "         [0.8945],\n",
       "         [0.4297],\n",
       "         [0.4766],\n",
       "         [0.5195],\n",
       "         [0.6094],\n",
       "         [0.1592],\n",
       "         [0.6641],\n",
       "         [0.7227],\n",
       "         [0.4219],\n",
       "         [0.0791],\n",
       "         [0.1689],\n",
       "         [0.1064],\n",
       "         [0.7656],\n",
       "         [0.2061],\n",
       "         [0.3848],\n",
       "         [0.4668],\n",
       "         [0.8594],\n",
       "         [0.2266],\n",
       "         [0.3340],\n",
       "         [0.3770],\n",
       "         [0.4961],\n",
       "         [0.7266],\n",
       "         [0.8281],\n",
       "         [0.2363],\n",
       "         [0.5898],\n",
       "         [0.2559],\n",
       "         [0.6016],\n",
       "         [0.2275],\n",
       "         [1.0000],\n",
       "         [0.7852],\n",
       "         [0.6094],\n",
       "         [0.5898],\n",
       "         [0.3145]], device='xpu:0', dtype=torch.bfloat16),\n",
       " tensor([[0.0625],\n",
       "         [0.6367],\n",
       "         [0.9727],\n",
       "         [0.8086],\n",
       "         [0.5469],\n",
       "         [0.4629],\n",
       "         [0.4141],\n",
       "         [0.3906],\n",
       "         [0.6836],\n",
       "         [0.5273],\n",
       "         [0.8594],\n",
       "         [0.8438],\n",
       "         [0.2119],\n",
       "         [0.8203],\n",
       "         [0.9727],\n",
       "         [0.5078],\n",
       "         [0.6758],\n",
       "         [0.4238],\n",
       "         [0.9375],\n",
       "         [0.7188],\n",
       "         [0.8828],\n",
       "         [0.3984],\n",
       "         [0.5039],\n",
       "         [0.5742],\n",
       "         [0.7109],\n",
       "         [0.8750],\n",
       "         [0.4414],\n",
       "         [0.3691],\n",
       "         [0.8555],\n",
       "         [0.1934],\n",
       "         [0.9922],\n",
       "         [0.2490],\n",
       "         [0.2578],\n",
       "         [0.1426],\n",
       "         [0.1006],\n",
       "         [0.2891],\n",
       "         [0.0713],\n",
       "         [0.1445],\n",
       "         [0.2031],\n",
       "         [0.4258],\n",
       "         [0.6953],\n",
       "         [0.1729],\n",
       "         [0.2656],\n",
       "         [0.8125],\n",
       "         [0.7891],\n",
       "         [0.3691],\n",
       "         [0.3828],\n",
       "         [0.2275],\n",
       "         [0.7461],\n",
       "         [0.4160],\n",
       "         [0.7656],\n",
       "         [0.3848],\n",
       "         [0.5469],\n",
       "         [0.1377],\n",
       "         [0.4141],\n",
       "         [0.9570],\n",
       "         [0.1050],\n",
       "         [0.0684],\n",
       "         [0.1377],\n",
       "         [0.6641],\n",
       "         [0.4551],\n",
       "         [0.5664],\n",
       "         [0.2578],\n",
       "         [0.0381],\n",
       "         [0.0613],\n",
       "         [0.4434],\n",
       "         [0.0283],\n",
       "         [0.0420],\n",
       "         [0.7461],\n",
       "         [0.6172],\n",
       "         [0.6836],\n",
       "         [0.6875],\n",
       "         [0.6094],\n",
       "         [0.8125],\n",
       "         [0.7422],\n",
       "         [0.9453],\n",
       "         [0.7305],\n",
       "         [0.9844],\n",
       "         [0.3125],\n",
       "         [0.8359],\n",
       "         [0.4160],\n",
       "         [0.6602],\n",
       "         [0.4980],\n",
       "         [0.6406],\n",
       "         [0.0767],\n",
       "         [0.7539],\n",
       "         [0.0391],\n",
       "         [0.1924],\n",
       "         [0.3379],\n",
       "         [0.3516],\n",
       "         [0.8789],\n",
       "         [0.5508],\n",
       "         [0.7500],\n",
       "         [0.5703],\n",
       "         [0.4316],\n",
       "         [0.2412],\n",
       "         [0.4199],\n",
       "         [0.3926],\n",
       "         [0.0439],\n",
       "         [0.8047],\n",
       "         [0.8359],\n",
       "         [0.0991],\n",
       "         [0.3887],\n",
       "         [0.2676],\n",
       "         [0.3242],\n",
       "         [0.2891],\n",
       "         [0.8906],\n",
       "         [0.1826],\n",
       "         [0.1953],\n",
       "         [0.3555],\n",
       "         [0.3184],\n",
       "         [0.5391],\n",
       "         [0.3691],\n",
       "         [0.3125],\n",
       "         [0.8320],\n",
       "         [0.5742],\n",
       "         [0.9727],\n",
       "         [0.1226],\n",
       "         [0.9219],\n",
       "         [0.4824],\n",
       "         [0.0645],\n",
       "         [0.8477],\n",
       "         [0.6836],\n",
       "         [0.6719],\n",
       "         [0.1279],\n",
       "         [0.7500],\n",
       "         [0.4629],\n",
       "         [0.3789]], device='xpu:0', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.rand((128,3)).to(torch.device('xpu:0'), dtype=torch.bfloat16)\n",
    "a = torch.rand((128,1)).to(torch.device('xpu:0'), dtype=torch.bfloat16)\n",
    "t = torch.rand((128,1)).to(torch.device('xpu:0'), dtype=torch.bfloat16)\n",
    "# o = torch.rand((128,1)).to(torch.device('cpu'), dtype=torch.bfloat16)\n",
    "# a = torch.rand((128,1)).to(torch.device('cpu'), dtype=torch.bfloat16)\n",
    "# t = torch.rand((128,1)).to(torch.device('cpu'), dtype=torch.bfloat16)\n",
    "o, a, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = torch.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "could not execute a primitive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Q\u001b[39m.\u001b[39;49mfit(o, a, t)\n",
      "File \u001b[0;32m~/bwSyncAndShare/stud/mast/Sem2/RL/project/RLPowerPucks/algorithms/td3_code_tmp/div/Q_file.py:46\u001b[0m, in \u001b[0;36mQ_net.fit\u001b[0;34m(self, o, a, t)\u001b[0m\n\u001b[1;32m     43\u001b[0m             q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mQ_calc(o, a)\n\u001b[1;32m     44\u001b[0m     loss_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(q, t)\n\u001b[0;32m---> 46\u001b[0m loss_val\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m loss_val\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/mambaforge/envs/rl/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/rl/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: could not execute a primitive"
     ]
    }
   ],
   "source": [
    "Q.fit(o, a, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
